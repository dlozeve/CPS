#+TITLE: CPS4: The Black-Scholes hedging strategy
#+AUTHOR: Dimitri Lozeve
#+EMAIL: dimitri.lozeve@polytechnique.edu

#+PROPERTY: header-args :tangle yes
#+HTML_MATHJAX:  path:"http://cdn.mathjax.org/mathjax/latest/MathJax.js"

* Sequential

#+BEGIN_SRC ipython :session :exports both
  import numpy as np
  import scipy.stats as stats
  import matplotlib.pyplot as plt
  %matplotlib inline
  plt.style.use("ggplot")
#+END_SRC

#+RESULTS:

#+BEGIN_SRC ipython :session :exports both
  def geombrownian(T, mu, sigma, S0, n):
      """Computes a geometric Brownian motion (price of the risky asset).

      """
      dt = 2**(-n) * T
      t = np.linspace(0, T, 2**n)
      W = np.random.standard_normal(size = 2**n)
      W = np.cumsum(W) * np.sqrt(dt)
      X = (mu - sigma**2/2)*t + sigma*W
      return S0 * np.exp(X)
#+END_SRC

#+RESULTS:

We plot a sample geometric Brownian motion:

#+BEGIN_SRC ipython :session :file /home/dimitri/cours/3A/MAP552/CPS/CPS4/py529WKw.png :exports both
  T = 1
  mu = 0.05
  sigma = 0.3
  S0 = 100
  n = 12

  t = np.linspace(0, T, 2**n)
  S = geombrownian(T, mu, sigma, S0, n)

  plt.plot(t, S)
#+END_SRC

#+RESULTS:
[[file:/home/dimitri/cours/3A/MAP552/CPS/CPS4/py529WKw.png]]


The following program computes $N = 1000$ samples of the geometric
Brownian motion, and returns its mean and variance, for $\mu = 0.05$,
$0.02$, and $0.45$.

#+BEGIN_SRC ipython :session :exports both
  T = 1
  sigma = 0.3
  mus = [0.05, 0.02, 0.45]
  S0 = 100
  n = 12

  N = 1000

  mean = [0,0,0]
  var = [0,0,0]
  for i in range(len(mus)):
      Ws = np.zeros((N,2**n))
      for j in range(N):
          Ws[j] = geombrownian(T, mus[i], sigma, S0, n)
      mean[i] = np.mean(Ws)
      var[i] = np.var(Ws)

  mus,mean,var
#+END_SRC

#+RESULTS:
|               0.05 |               0.02 |               0.45 |
| 102.10018976352907 |  99.82838777197556 | 127.58345417707866 |
| 447.72316435673247 | 450.00229961228433 | 1116.7443669636068 |

When the drift becomes higher, the mean deviates from the start point
(100), and the variance becomes higher.


#+BEGIN_SRC ipython :session :exports both
  def dplus(s, k, v):
      return np.log(s/k)/np.sqrt(v) + np.sqrt(v)/2

  def dminus(s, k, v):
      return np.log(s/k)/np.sqrt(v) - np.sqrt(v)/2

  def BS(S0, K, T, sigma, r):
      """Black-Scholes price of a European call option.

      """
      part1 = stats.norm.cdf(dplus(S0, K*np.exp(-r*T), sigma**2*T))
      part2 = stats.norm.cdf(dminus(S0, K*np.exp(-r*T), sigma**2*T))
      return S0*part1 - K*np.exp(-r*T)*part2

  def delta(S, K, t, sigma, r):
      """Optimal hedging strategy.

      """
      return stats.norm.cdf(dplus(S, K*np.exp(-r*t), sigma**2*t))

  def X(T, n, K, S0, mu, sigma, r):
      res = 0
      t = np.linspace(0, T, 2**n)
      S = geombrownian(T, mu, sigma, S0, n)
      res = np.exp(-r*t)*S
      res = res[1:] - res[:-1]
      deltas = np.zeros(2**n - 1)
      for i in range(2**n-1):
          deltas[i] = delta(S[i], K, T-t[i], sigma, r)
      res = deltas.dot(res)
      # res = delta(S[0], K, T-t[0], sigma, r) *\
      #       np.exp(-r*t[0])*S[0]
      # for i in range(1,2**n):
      #     res += delta(S[i-1], K, T-t[i-1], sigma, r) *\
      #            (np.exp(-r*t[i])*S[i] - np.exp(-r*t[i-1]*S[i-1]))
      res += BS(S0, K, T, sigma, r)
      return np.exp(-r*T) * res
#+END_SRC

#+RESULTS:


Serial version of the code, DO NOT RUN. (Takes a very long time.)

#+BEGIN_SRC ipython :session :exports both :eval no
  T = 1
  n = 10
  S0 = 100
  mus = [0.05, 0.02, 0.45]
  sigma = 0.3
  r = 0.05
  N = 1000

  Xs = np.zeros((3,40,N))

  for i in range(1):
      mu = mus[i]
      for j in range(20):
          K = 100 + j
          for k in range(N):
              Xs[i,j,k] = X(T, n, K, S0, mu, sigma, r)
  Xs
#+END_SRC


* Parallel version

Loading the parallel library (example with 8 cores).

#+BEGIN_SRC ipython :session :exports both :eval no
  from ipyparallel import Client
  rc = Client()
  dv = rc[:]
  rc.ids
#+END_SRC

#+RESULTS:
| 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 |

We load the necessary libraries on every core:

#+BEGIN_SRC ipython :session :exports both :results output :eval no
  with dv.sync_imports():
      import numpy
      import scipy
      import scipy.stats
#+END_SRC

#+RESULTS:
: importing numpy on engine(s)
: importing scipy on engine(s)
: importing scipy.stats on engine(s)

New definitions, distributed to each core (same functions as before).

#+BEGIN_SRC ipython :session :exports both :eval no
  %%px

  # Parallel version

  def geombrownian(T, mu, sigma, S0, n):
      dt = 2**(-n) * T
      t = numpy.linspace(0, T, 2**n)
      W = numpy.random.standard_normal(size = 2**n)
      W = numpy.cumsum(W) * numpy.sqrt(dt)
      X = (mu - sigma**2/2)*t + sigma*W
      return S0 * numpy.exp(X)

  def dplus(s, k, v):
      return numpy.log(s/k)/numpy.sqrt(v) + numpy.sqrt(v)/2

  def dminus(s, k, v):
      return numpy.log(s/k)/numpy.sqrt(v) - numpy.sqrt(v)/2

  def BS(S0, K, T, sigma, r):
      part1 = scipy.stats.norm.cdf(dplus(S0, K*numpy.exp(-r*T), sigma**2*T))
      part2 = scipy.stats.norm.cdf(dminus(S0, K*numpy.exp(-r*T), sigma**2*T))
      return S0*part1 - K*numpy.exp(-r*T)*part2

  def delta(S, K, t, sigma, r):
      return scipy.stats.norm.cdf(dplus(S, K*numpy.exp(-r*t), sigma**2*t))

  def X(T, n, K, S0, mu, sigma, r):
      res = 0
      t = numpy.linspace(0, T, 2**n)
      S = geombrownian(T, mu, sigma, S0, n)
      res = numpy.exp(-r*t)*S
      res = res[1:] - res[:-1]
      deltas = numpy.zeros(2**n - 1)
      for i in range(2**n-1):
          deltas[i] = delta(S[i], K, T-t[i], sigma, r)
      res = deltas.dot(res)
      # res = delta(S[0], K, T-t[0], sigma, r) *\
      #       numpy.exp(-r*t[0])*S[0]
      # for i in range(1,2**n):
      #     res += delta(S[i-1], K, T-t[i-1], sigma, r) *\
      #            (numpy.exp(-r*t[i])*S[i] - numpy.exp(-r*t[i-1]*S[i-1]))
      res += BS(S0, K, T, sigma, r)
      return numpy.exp(-r*T) * res
#+END_SRC

#+RESULTS:


#+BEGIN_SRC ipython :session :exports both :eval no
  %%px

  T = 1
  n = 10
  S0 = 100
  sigma = 0.3
  r = 0.05
  N = 1000
#+END_SRC

#+RESULTS:

For $\mu = 0.05$, we create an array with $N = 1000$ values for each
$K$. We scatter the resulting array on the computing cores, run the
function in parallel, and gather the results.

#+BEGIN_SRC ipython :session :exports both :eval no
  %px mu = 0.05
  N = 1000
  dv.scatter('mu1', numpy.repeat(numpy.arange(100-20,100+20+1), N))
  #dv.scatter('mu1', numpy.ones(N)*80)
  %px xs1 = [X(T, n, K, S0, mu, sigma, r) for K in mu1]
  xs1 = dv.gather('xs1')
#+END_SRC

#+RESULTS:

#+BEGIN_SRC ipython :session :exports both :eval no
  numpy.array(xs1.get())
#+END_SRC

#+RESULTS:
: array([  6.76823399e+01,   4.72614591e+01,   1.39741887e+01, ...,
:          7.24084135e+00,   1.04901807e+01,  -3.98152211e-03])


Same procedure for $\mu = 0.02$.

#+BEGIN_SRC ipython :session :exports both :eval no
  %px mu = 0.02
  N = 1000
  dv.scatter('mu2', numpy.repeat(numpy.arange(100-20,100+20+1), N))
  %px xs2 = [X(T, n, K, S0, mu, sigma, r) for K in mu2]
  xs2 = dv.gather('xs2')
#+END_SRC

#+RESULTS:

#+BEGIN_SRC ipython :session :exports both :eval no
  numpy.array(xs2.get())
#+END_SRC

#+RESULTS:
: array([ 77.91610039,  32.37486778,  70.46721201, ...,  -0.37952079,
:          0.19884309,   0.38395676])

$\mu = 0.45$.

#+BEGIN_SRC ipython :session :exports both :eval no
  %px mu = 0.45
  N = 1000
  dv.scatter('mu3', numpy.repeat(numpy.arange(100-20,100+20+1), N))
  %px xs3 = [X(T, n, K, S0, mu, sigma, r) for K in mu3]
  xs3 = dv.gather('xs3')
#+END_SRC

#+RESULTS:

#+BEGIN_SRC ipython :session :exports both :eval no
  numpy.array(xs3.get())
#+END_SRC

#+RESULTS:
: array([ 134.55741864,   72.83827336,   22.5866849 , ...,   11.21969658,
:           0.70331592,   31.36067831])

#+BEGIN_SRC ipython :session :exports both :eval no
  Xs = np.array([np.array(xs1.get()), np.array(xs2.get()), np.array(xs3.get())])
#+END_SRC

#+RESULTS:



* Amazon AWS

#+BEGIN_SRC ipython :session :exports both
  importedXs = np.load("outputXs.npy")
#+END_SRC

#+RESULTS:

